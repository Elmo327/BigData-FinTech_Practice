{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import struct\n",
    "import sys\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "    \"\"\"이미지 디렉토리에서 인풋 데이터를 찾아 데이터로 변환한다\"\"\"\n",
    "    \n",
    "    ## image_dir가 존재하지 않는다면 오류 출력\n",
    "    if not gfile.Exists(image_dir):\n",
    "        print(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "        return None\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    ### image_dir 내 하위 디렉토리(label)를 가져온다 \n",
    "    sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n",
    "    \n",
    "    is_root_dir = True\n",
    "    for sub_dir in sub_dirs:\n",
    "        if is_root_dir:\n",
    "            is_root_dir = False\n",
    "            continue\n",
    "        extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "        \n",
    "        file_list = []\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        if dir_name == image_dir:\n",
    "            continue\n",
    "            \n",
    "        print(\"Looking for images in '\" + dir_name + \"'\")\n",
    "        for extension in extensions:\n",
    "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "            file_list.extend(gfile.Glob(file_glob))\n",
    "        \n",
    "        ## 파일이 없거나 데이터가 작으면 예외 처리\n",
    "        if not file_list:\n",
    "            print('No files found')\n",
    "            continue\n",
    "        if len(file_list) < 20:\n",
    "            print(\"WARNING: Folder has less than 20 images, which may cause issues.\")\n",
    "        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "            print(\"WARNING: Folder {} has more than {} images. Some images will never be selected\".format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "        \n",
    "        ## 트레이닝 / 밸리데이션 / 테스트셋으로 나눈다.\n",
    "        training_images = []\n",
    "        testing_images = []\n",
    "        validation_images = []\n",
    "        for file_name in file_list:\n",
    "            base_name = os.path.basename(file_name)\n",
    "            \n",
    "            hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "            percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                               (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n",
    "                              (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "            \n",
    "            if percentage_hash < validation_percentage:\n",
    "                validation_images.append(base_name)\n",
    "            elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "                testing_images.append(base_name)\n",
    "            else:\n",
    "                training_images.append(base_name)\n",
    "        \n",
    "        result[label_name] = {\n",
    "            'dir': dir_name,\n",
    "            'training': training_images,\n",
    "            'testing': testing_images,\n",
    "            'validation': validation_images,\n",
    "        }\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "MODEL_INPUT_WIDTH = 299\n",
    "MODEL_INPUT_HEIGHT = 299\n",
    "MODEL_INPUT_DEPTH = 3\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_graph():\n",
    "    \"\"\"\n",
    "    저장된 GraphDef 파일에서 그래프를 만들고\n",
    "    Graph 오브젝트를 리턴한다.\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_filename = os.path.join(model_dir, 'classify_image_graph_def.pb')\n",
    "    \n",
    "        with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "                tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "                    BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME, RESIZED_INPUT_TENSOR_NAME]))\n",
    "    return graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_distort_images(flip_left_right, random_crop, random_scale, random_brightness):\n",
    "    \"\"\"이미지 데이터에 변화를 줄지 결정한다.\"\"\"\n",
    "    return (flip_left_right or (random_crop != 0) or (random_scale != 0) or (random_brightness != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir_exists(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, \\\n",
    "                             bottleneck_dir, jpeg_data_tensor, bottleneck_tensor):\n",
    "    label_lists = image_lists[label_name]\n",
    "    sub_dir = label_lists['dir']\n",
    "    sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "    ensure_dir_exists(sub_dir_path)\n",
    "    bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n",
    "                                    bottleneck_dir, category)\n",
    "    if not os.path.exists(bottleneck_path):\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                               image_dir, category, sess, jpeg_data_tensor,\n",
    "                               bottleneck_tensor)\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "        bottleneck_string = bottleneck_file.read()\n",
    "    \n",
    "    did_hit_error = False\n",
    "    try:\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    except ValueError:\n",
    "        print('Invalid float found, recreating bottleneck')\n",
    "        did_hit_error = True\n",
    "    if did_hit_error:\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                               image_dir, category, sess, jpeg_data_tensor,\n",
    "                               bottleneck_tensor)\n",
    "        with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "            bottleneck_string = bottleneck_file.read()\n",
    "        # Allow exceptions to propagate here, since they shouldn't happen after a\n",
    "        # fresh creation\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor):\n",
    "    how_many_bottlenecks = 0\n",
    "    ensure_dir_exists(bottleneck_dir)\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, \\\n",
    "                                         bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)\n",
    "                how_many_bottlenecks += 1\n",
    "                if how_many_bottlenecks % 100 == 0:\n",
    "                    print('{} bottleneck files created'.format(how_many_bottlenecks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category):\n",
    "    return get_image_path(image_lists, label_name, index, bottleneck_dir, category) + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "    \n",
    "    if label_name not in image_lists:\n",
    "        tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "    label_lists = image_lists[label_name]\n",
    "    \n",
    "    if category not in label_lists:\n",
    "        tf.logging.fatal('Category does not exist %s.', category)\n",
    "    category_list = label_lists[category]\n",
    "    \n",
    "    if not category_list:\n",
    "        tf.logging.fatal('Label %s has no images in the category %s.', label_name, category)\n",
    "        \n",
    "    mod_index = index % len(category_list)\n",
    "    base_name = category_list[mod_index]\n",
    "    sub_dir = label_lists['dir']\n",
    "    full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "    \n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir,\n",
    "                          category, sess, jpeg_data_tensor, bottleneck_tensor):\n",
    "    print('보틀넥 파일 생성 시작 - {}'.format(bottleneck_path))\n",
    "    image_path = get_image_path(image_lists, label_name, index, image_dir, category)\n",
    "    \n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fata('File does nto exist %s', image_path)\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    \n",
    "    try:\n",
    "        bottleneck_values = run_bottleneck_on_image(\n",
    "            sess, image_data, jpeg_data_tensor, bottleneck_tensor)\n",
    "    except:\n",
    "        raise RuntimeError('파일 처리 중 에러 발생: %s' % image_path)\n",
    "        \n",
    "    bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "    with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "        bottleneck_file.write(bottleneck_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor, bottleneck_tensor):\n",
    "    bottleneck_values = sess.run(\n",
    "        bottleneck_tensor, {image_data_tensor: image_data})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor):\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(\n",
    "            bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],\n",
    "            name='BottleneckInputPlaceholder')\n",
    "        \n",
    "        ground_truth_input = tf.placeholder(tf.float32, [None, class_count], name='GroundTruthInput')\n",
    "        \n",
    "    layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, class_count], stddev=0.01)\n",
    "            \n",
    "            layer_weights = tf.Variable(initial_value, name='final_weight')\n",
    "        \n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "            \n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "    \n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=ground_truth_input, logits=logits)\n",
    "        with tf.name_scope('total'):\n",
    "            cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "        \n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input, final_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(\n",
    "                prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category, bottleneck_dir, image_dir,\n",
    "                                 jpeg_data_tensor, bottleneck_tensor):\n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    filenames = []\n",
    "    if how_many >= 0:\n",
    "        # 샘플링한 보틀넥을 가져온다.\n",
    "        for unused_i in range(how_many):\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = list(image_lists.keys())[label_index]\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "            image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                      image_dir, category)\n",
    "            bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n",
    "                                                image_index, image_dir, category,\n",
    "                                                bottleneck_dir, jpeg_data_tensor,\n",
    "                                                bottleneck_tensor)\n",
    "            ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "            ground_truth[label_index] = 1.0\n",
    "            bottlenecks.append(bottleneck)\n",
    "            ground_truths.append(ground_truth)\n",
    "            filenames.append(image_name)\n",
    "    else:\n",
    "        # 보틀넥을 모두 가져온다.\n",
    "        for label_index, label_name in enumerate(image_lists.keys()):\n",
    "            for image_index, image_name in enumerate(image_lists[label_name][category]):\n",
    "                image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                            image_dir, category)\n",
    "                bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n",
    "                                                      image_index, image_dir, category,\n",
    "                                                      bottleneck_dir, jpeg_data_tensor,\n",
    "                                                      bottleneck_tensor)\n",
    "                ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "                ground_truth[label_index] = 1.0\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(ground_truth)\n",
    "                filenames.append(image_name)\n",
    "    return bottlenecks, ground_truths, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'D:\\\\DL_picture_data'\n",
    "output_graph = '/tmp/output_graph.pb'\n",
    "output_labels = '/tmp/output_labels.txt'\n",
    "summaries_dir = '/tmp/retrain_logs'\n",
    "how_many_training_steps = 300\n",
    "learning_rate = 0.01\n",
    "testing_percentage = 10\n",
    "validation_percentage = 10\n",
    "eval_step_interval = 10\n",
    "train_batch_size = 100\n",
    "test_batch_size = -1\n",
    "validation_batch_size = 100\n",
    "print_misclassified_test_images = False\n",
    "model_dir = '/tmp/imagenet'\n",
    "bottleneck_dir = '/tmp/bottleneck'\n",
    "final_tensor_name = 'final_result'\n",
    "flip_left_right = False\n",
    "random_crop = 0\n",
    "random_scale = 0\n",
    "random_brightness = 0 \n",
    "log_frequency = 10\n",
    "log_device_placement = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, bottleneck_tensor, jpeg_data_tensor, resize_image_tensor = (create_inception_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 362\n"
     ]
    }
   ],
   "source": [
    "image_lists = create_image_lists(image_dir, testing_percentage, validation_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = len(image_lists.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 해당 경로에 없습니다: D:\\DL_picture_data\n"
     ]
    }
   ],
   "source": [
    "if class_count == 0:\n",
    "    print('이미지가 해당 경로에 없습니다: ' + image_dir)\n",
    "    \n",
    "elif class_count == 1:\n",
    "    print('해당 경로에 클래스가 1개만 발견되었습니다: ' + image_dir + ' - 분류를 위해 2개 이상의 클래스가 필요합니다.')\n",
    "    \n",
    "else:\n",
    "    print(\"클래스가 2개 이상 있습니다. 학습을 시작합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_distort_images = should_distort_images(flip_left_right, random_crop, random_scale, random_brightness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-78e14a942f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0macc_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdo_distort_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         (distorted_jpeg_data_tensor, distorted_image_tensor) = add_input_distortion(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    if do_distort_images:\n",
    "        (distorted_jpeg_data_tensor, distorted_image_tensor) = add_input_distortion(\n",
    "            flip_left_right, random_crop, random_scale, random_brightness)\n",
    "    else:\n",
    "        cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)\n",
    "    \n",
    "    ## 네트워크의 끝에 우리가 원하는 분류 레이어를 붙인다.\n",
    "    (train_step, cross_entropy, bottleneck_input, \n",
    "     ground_truth_input, final_tensor) = add_final_training_ops(len(image_lists.keys()), \n",
    "                                                                final_tensor_name, \n",
    "                                                                bottleneck_tensor)\n",
    "        \n",
    "    ## 정확도 평가를 위한 새로운 오퍼레이션\n",
    "    evaluation_step, prediction = add_evaluation_step(final_tensor, ground_truth_input)\n",
    "    \n",
    "    ## 가중치 초기화\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(how_many_training_steps):\n",
    "        \n",
    "        ## 보틀넥과 정답지를 준비한다.\n",
    "        if do_distort_images:\n",
    "            (train_bottlenecks, train_ground_truth) = get_random_distorted_bottlenecks(\n",
    "                sess, image_lists, train_batch_size, 'training', image_dir, distorted_jpeg_data_tensor,\n",
    "                distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n",
    "        else:\n",
    "            (train_bottlenecks, train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "                sess, image_lists, train_batch_size, 'training', bottleneck_dir, image_dir,\n",
    "                jpeg_data_tensor, bottleneck_tensor)\n",
    "        \n",
    "        \n",
    "        ## 보틀넥과 정답지를 모델에 집어넣어 학습시킨다.\n",
    "        _ = sess.run(\n",
    "            [train_step],\n",
    "            feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                      ground_truth_input: train_ground_truth})\n",
    "    \n",
    "        ## 특정 구간마다 트레이닝 정확도와 cross entropy 로그, 밸리데이션 정확도를 출력한다.\n",
    "        is_last_step = (i + 1 == how_many_training_steps)\n",
    "        if (i % eval_step_interval) == 0 or is_last_step:\n",
    "            train_accuracy, cross_entropy_value = sess.run(\n",
    "                [evaluation_step, cross_entropy],\n",
    "                feed_dict = {bottleneck_input: train_bottlenecks,\n",
    "                            ground_truth_input: train_ground_truth})\n",
    "            \n",
    "            print('%s: Step %d: Train accuracy = %.1f%%'% (datetime.now(), i, train_accuracy * 100))\n",
    "            print('%s: Step %d: Cross entropy = %f' % (datetime.now(), i, cross_entropy_value))\n",
    "            \n",
    "            validation_bottlenecks, validation_ground_truth, _ = (\n",
    "                get_random_cached_bottlenecks(\n",
    "                    sess, image_lists, validation_batch_size, 'validation', bottleneck_dir,\n",
    "                    image_dir, jpeg_data_tensor, bottleneck_tensor))\n",
    "            \n",
    "            validation_accuracy = sess.run(\n",
    "                evaluation_step,\n",
    "                feed_dict = {bottleneck_input: validation_bottlenecks,\n",
    "                            ground_truth_input: validation_ground_truth})\n",
    "            print('%s: Step %d: Validation accuracy = %.1f%% (N=%d)'% (datetime.now(), i,\n",
    "                                                                       validation_accuracy * 100, \n",
    "                                                                       len(validation_bottlenecks)))\n",
    "            \n",
    "            ## 시각화를 위해 로그를 한벌 더 저장한다.\n",
    "            acc_list.append({\"epoch\": i, \"train_accuracy\": train_accuracy, \"validation_accuracy\": validation_accuracy})\n",
    "    \n",
    "    ## 테스트셋에 사용할 보틀넥과 정답지를 가져온다.\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(sess, image_lists, test_batch_size, 'testing', bottleneck_dir,\n",
    "                                     image_dir, jpeg_data_tensor, bottleneck_tensor))\n",
    "    \n",
    "    ## 테스트셋 정확도와 예측 분류값을 가져온다.\n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction], \n",
    "        feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                  ground_truth_input: test_ground_truth})\n",
    "    print('최종 학습 정확도 = %.1f%% (N=%d)' % (test_accuracy * 100, len(test_bottlenecks)))\n",
    "    \n",
    "    output_graph_def = graph_util.convert_variables_to_constants(\n",
    "        sess, graph.as_graph_def(), [final_tensor_name])\n",
    "    with gfile.FastGFile(output_graph, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    with gfile.FastGFile(output_labels, 'w') as f:\n",
    "        f.write('\\n'.join(image_lists.keys()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2525\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'epoch'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ea1c24af7671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0macc_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0macc_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   3144\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3146\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3147\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3843\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3844\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2525\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2527\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'epoch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "acc_df = pd.DataFrame.from_dict(acc_list)\n",
    "acc_df.set_index('epoch', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Empty 'DataFrame': no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-89ab4353540b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[0;32m   2675\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2676\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2677\u001b[1;33m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[0;32m   2678\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[1;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[0;32m   1900\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1902\u001b[1;33m                  **kwds)\n\u001b[0m\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_plot\u001b[1;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[0;32m   1727\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1729\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1730\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             raise TypeError('Empty {0!r}: no numeric data to '\n\u001b[1;32m--> 365\u001b[1;33m                             'plot'.format(numeric_data.__class__.__name__))\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Empty 'DataFrame': no numeric data to plot"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
